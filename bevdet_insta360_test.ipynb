{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aafcf0-dc26-461a-b2b8-1e348dd3845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.cnn import fuse_conv_bn\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,wrap_fp16_model)\n",
    "\n",
    "import mmdet\n",
    "from mmdet3d.apis import single_gpu_test\n",
    "from mmdet3d.datasets import build_dataloader, build_dataset\n",
    "from mmdet3d.models import build_model\n",
    "from mmdet.apis import multi_gpu_test, set_random_seed\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "\n",
    "if mmdet.__version__ > '2.23.0':\n",
    "    # If mmdet version > 2.23.0, setup_multi_processes would be imported and\n",
    "    # used from mmdet instead of mmdet3d.\n",
    "    from mmdet.utils import setup_multi_processes\n",
    "else:\n",
    "    from mmdet3d.utils import setup_multi_processes\n",
    "\n",
    "try:\n",
    "    # If mmdet version > 2.23.0, compat_cfg would be imported and\n",
    "    # used from mmdet instead of mmdet3d.\n",
    "    from mmdet.utils import compat_cfg\n",
    "except ImportError:\n",
    "    from mmdet3d.utils import compat_cfg\n",
    "    \n",
    "import json\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "from mmdet3d.core.bbox.structures.lidar_box3d import LiDARInstance3DBoxes as LB\n",
    "\n",
    "from nuscenes.utils.data_classes import Box, LidarPointCloud\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "from PIL import Image\n",
    "from pyquaternion import Quaternion\n",
    "import pyquaternion\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "from math import pi\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "# PoseNet\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68afc021-0571-4bbd-890f-75f7b477d96a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pose Network (from Manydepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c3bb19-4227-488d-bcce-f5dbcb0bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_from_parameters(axisangle, translation, invert=False):\n",
    "    \"\"\"Convert the network's (axisangle, translation) output into a 4x4 matrix\n",
    "    \"\"\"\n",
    "    R = rot_from_axisangle(axisangle)\n",
    "    t = translation.clone()\n",
    "\n",
    "    if invert:\n",
    "        R = R.transpose(1, 2)\n",
    "        t *= -1\n",
    "\n",
    "    T = get_translation_matrix(t)\n",
    "    \n",
    "    # print(\"R: \", R)\n",
    "    # print(\"R[:3, :3]: \", R[:, :3, :3])\n",
    "    # print(\"T: \", T)\n",
    "    # print(\"T[~]: \", T[:, :3, -1])\n",
    "    \n",
    "    # R, T를 이어 붙여서 return\n",
    "    M = R.new_zeros((4, 4))\n",
    "    M[3, 3] = 1\n",
    "    M[:3, :3] = R[:, :3, :3]\n",
    "    M[:3, -1] = T[:, :3, -1]\n",
    "\n",
    "    # R, T 간의 행렬곱을 return\n",
    "    # if invert:\n",
    "    #     M = torch.matmul(R, T)\n",
    "    # else:\n",
    "    #     M = torch.matmul(T, R)\n",
    "\n",
    "    return M\n",
    "\n",
    "def get_translation_matrix(translation_vector):\n",
    "    \"\"\"Convert a translation vector into a 4x4 transformation matrix\n",
    "    \"\"\"\n",
    "    T = torch.zeros(translation_vector.shape[0], 4, 4).to(device=translation_vector.device)\n",
    "\n",
    "    t = translation_vector.contiguous().view(-1, 3, 1)\n",
    "\n",
    "    T[:, 0, 0] = 1\n",
    "    T[:, 1, 1] = 1\n",
    "    T[:, 2, 2] = 1\n",
    "    T[:, 3, 3] = 1\n",
    "    T[:, :3, 3, None] = t\n",
    "\n",
    "    return T\n",
    "\n",
    "def rot_from_axisangle(vec):\n",
    "    \"\"\"Convert an axisangle rotation into a 4x4 transformation matrix\n",
    "    (adapted from https://github.com/Wallacoloo/printipi)\n",
    "    Input 'vec' has to be Bx1x3\n",
    "    \"\"\"\n",
    "    angle = torch.norm(vec, 2, 2, True)\n",
    "    axis = vec / (angle + 1e-7)\n",
    "\n",
    "    ca = torch.cos(angle)\n",
    "    sa = torch.sin(angle)\n",
    "    C = 1 - ca\n",
    "\n",
    "    x = axis[..., 0].unsqueeze(1)\n",
    "    y = axis[..., 1].unsqueeze(1)\n",
    "    z = axis[..., 2].unsqueeze(1)\n",
    "\n",
    "    xs = x * sa\n",
    "    ys = y * sa\n",
    "    zs = z * sa\n",
    "    xC = x * C\n",
    "    yC = y * C\n",
    "    zC = z * C\n",
    "    xyC = x * yC\n",
    "    yzC = y * zC\n",
    "    zxC = z * xC\n",
    "\n",
    "    rot = torch.zeros((vec.shape[0], 4, 4)).to(device=vec.device)\n",
    "\n",
    "    rot[:, 0, 0] = torch.squeeze(x * xC + ca)\n",
    "    rot[:, 0, 1] = torch.squeeze(xyC - zs)\n",
    "    rot[:, 0, 2] = torch.squeeze(zxC + ys)\n",
    "    rot[:, 1, 0] = torch.squeeze(xyC + zs)\n",
    "    rot[:, 1, 1] = torch.squeeze(y * yC + ca)\n",
    "    rot[:, 1, 2] = torch.squeeze(yzC - xs)\n",
    "    rot[:, 2, 0] = torch.squeeze(zxC - ys)\n",
    "    rot[:, 2, 1] = torch.squeeze(yzC + xs)\n",
    "    rot[:, 2, 2] = torch.squeeze(z * zC + ca)\n",
    "    rot[:, 3, 3] = 1\n",
    "\n",
    "    return rot\n",
    "\n",
    "class ResNetMultiImageInput(models.ResNet):\n",
    "    \"\"\"Constructs a resnet model with varying number of input images.\n",
    "    Adapted from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, num_input_images=1):\n",
    "        super(ResNetMultiImageInput, self).__init__(block, layers)\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_input_images * 3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet_multiimage_input(num_layers, pretrained=False, num_input_images=1):\n",
    "    \"\"\"Constructs a ResNet model.\n",
    "    Args:\n",
    "        num_layers (int): Number of resnet layers. Must be 18 or 50\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        num_input_images (int): Number of frames stacked as input\n",
    "    \"\"\"\n",
    "    assert num_layers in [18, 50], \"Can only run with 18 or 50 layer resnet\"\n",
    "    blocks = {18: [2, 2, 2, 2], 50: [3, 4, 6, 3]}[num_layers]\n",
    "    block_type = {18: models.resnet.BasicBlock, 50: models.resnet.Bottleneck}[num_layers]\n",
    "    model = ResNetMultiImageInput(block_type, blocks, num_input_images=num_input_images)\n",
    "\n",
    "    if pretrained:\n",
    "        loaded = model_zoo.load_url(models.resnet.model_urls['resnet{}'.format(num_layers)])\n",
    "        loaded['conv1.weight'] = torch.cat(\n",
    "            [loaded['conv1.weight']] * num_input_images, 1) / num_input_images\n",
    "        model.load_state_dict(loaded)\n",
    "    return model\n",
    "\n",
    "\"\"\"Pose Encoder\"\"\"\n",
    "class ResnetEncoder(nn.Module):\n",
    "    \"\"\"Pytorch module for a resnet encoder\"\"\"\n",
    "    def __init__(self, num_layers, pretrained, num_input_images=1, **kwargs):\n",
    "        super(ResnetEncoder, self).__init__()\n",
    "\n",
    "        self.num_ch_enc = np.array([64, 64, 128, 256, 512])\n",
    "\n",
    "        resnets = {18: models.resnet18,\n",
    "                   34: models.resnet34,\n",
    "                   50: models.resnet50,\n",
    "                   101: models.resnet101,\n",
    "                   152: models.resnet152}\n",
    "\n",
    "        if num_layers not in resnets:\n",
    "            raise ValueError(\"{} is not a valid number of resnet layers\".format(num_layers))\n",
    "\n",
    "        if num_input_images > 1:\n",
    "            self.encoder = resnet_multiimage_input(num_layers, pretrained, num_input_images)\n",
    "        else:\n",
    "            self.encoder = resnets[num_layers](pretrained)\n",
    "\n",
    "        if num_layers > 34:\n",
    "            self.num_ch_enc[1:] *= 4\n",
    "\n",
    "    def forward(self, input_image):\n",
    "        self.features = []\n",
    "        x = (input_image - 0.45) / 0.225\n",
    "        x = self.encoder.conv1(x)\n",
    "        x = self.encoder.bn1(x)\n",
    "        self.features.append(self.encoder.relu(x))\n",
    "        self.features.append(self.encoder.layer1(self.encoder.maxpool(self.features[-1])))\n",
    "        self.features.append(self.encoder.layer2(self.features[-1]))\n",
    "        self.features.append(self.encoder.layer3(self.features[-1]))\n",
    "        self.features.append(self.encoder.layer4(self.features[-1]))\n",
    "\n",
    "        return self.features\n",
    "\n",
    "\"\"\"Pose Decoder\"\"\"\n",
    "class PoseDecoder(nn.Module):\n",
    "    def __init__(self, num_ch_enc, num_input_features, num_frames_to_predict_for=None, stride=1):\n",
    "        super(PoseDecoder, self).__init__()\n",
    "\n",
    "        self.num_ch_enc = num_ch_enc\n",
    "        self.num_input_features = num_input_features\n",
    "\n",
    "        if num_frames_to_predict_for is None:\n",
    "            num_frames_to_predict_for = num_input_features - 1\n",
    "        self.num_frames_to_predict_for = num_frames_to_predict_for\n",
    "\n",
    "        self.convs = OrderedDict()\n",
    "        self.convs[(\"squeeze\")] = nn.Conv2d(self.num_ch_enc[-1], 256, 1)\n",
    "        self.convs[(\"pose\", 0)] = nn.Conv2d(num_input_features * 256, 256, 3, stride, 1)\n",
    "        self.convs[(\"pose\", 1)] = nn.Conv2d(256, 256, 3, stride, 1)\n",
    "        self.convs[(\"pose\", 2)] = nn.Conv2d(256, 6 * num_frames_to_predict_for, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.net = nn.ModuleList(list(self.convs.values()))\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        last_features = [f[-1] for f in input_features]\n",
    "\n",
    "        cat_features = [self.relu(self.convs[\"squeeze\"](f)) for f in last_features]\n",
    "        cat_features = torch.cat(cat_features, 1)\n",
    "\n",
    "        out = cat_features\n",
    "        for i in range(3):\n",
    "            out = self.convs[(\"pose\", i)](out)\n",
    "            if i != 2:\n",
    "                out = self.relu(out)\n",
    "\n",
    "        out = out.mean(3).mean(2)\n",
    "\n",
    "        out = 0.01 * out.view(-1, self.num_frames_to_predict_for, 1, 6)\n",
    "\n",
    "        axisangle = out[..., :3]\n",
    "        translation = out[..., 3:]\n",
    "\n",
    "        return axisangle, translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2db8effe-3b9c-45d9-83a8-66eba8a06ac6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tangent Patch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd805d25-0583-4743-a853-35a7f9dd7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createProjectGrid(erp_h, erp_w, tangent_h, tangent_w, num_rows, num_cols, phi_centers, fov):\n",
    "    height, width = tangent_h, tangent_w\n",
    "\n",
    "    FOV = fov\n",
    "    FOV = [FOV[0] / 360.0, FOV[1] / 180.0]\n",
    "    FOV = torch.tensor(FOV, dtype=torch.float32)\n",
    "\n",
    "    PI = math.pi\n",
    "    PI_2 = math.pi * 0.5\n",
    "    PI2 = math.pi * 2\n",
    "\n",
    "    yy, xx = torch.meshgrid(torch.linspace(0, 1, height), torch.linspace(0, 1, width))\n",
    "    screen_points = torch.stack([xx.flatten(), yy.flatten()], -1)\n",
    "\n",
    "    num_rows = num_rows\n",
    "    num_cols = num_cols\n",
    "    phi_centers = phi_centers\n",
    "\n",
    "    phi_interval = 180 // num_rows\n",
    "    all_combos = []\n",
    "    erp_mask = []\n",
    "\n",
    "    for i, n_cols in enumerate(num_cols):\n",
    "        for j in np.arange(n_cols): # 0 ~ num_cols.length\n",
    "            theta_interval = 360 / n_cols # 현재 row (위도)에서 쪼개질 경도 (col)의 위치\n",
    "            theta_center = j * theta_interval + theta_interval / 2\n",
    "            center = [theta_center, phi_centers[i]] # 각 tangent image의 center position\n",
    "\n",
    "            # print(str(j) + \" th theta center \" + str(theta_center) + \" phi center \" + str(phi_centers[i]))\n",
    "            \n",
    "            all_combos.append(center)\n",
    "\n",
    "            # 구좌표계에서의 tangent image가 차지하는 영역에 대한 좌표들\n",
    "            up = phi_centers[i] + phi_interval / 2\n",
    "            down = phi_centers[i] - phi_interval / 2\n",
    "            left = theta_center - theta_interval / 2\n",
    "            right = theta_center + theta_interval / 2\n",
    "\n",
    "            # ERP image에서 현재 tangent가 차지하는 영역에 대한 pixel 위치들\n",
    "            up = int((up + 90) / 180 * erp_h)\n",
    "            down = int((down + 90) / 180 * erp_h)\n",
    "            left = int(left / 360 * erp_w)\n",
    "            right = int(right / 360 * erp_w)\n",
    "\n",
    "            # ERP 이미지에서 현재 tangent image 영역에 해당하는 부분에 1로 마스킹\n",
    "            mask = np.zeros((erp_h, erp_w), dtype=int)\n",
    "            mask[down:up, left:right] = 1\n",
    "            erp_mask.append(mask)\n",
    "\n",
    "    all_combos = np.vstack(all_combos)\n",
    "    shifts = np.arange(all_combos.shape[0]) * width\n",
    "    shifts = torch.from_numpy(shifts).float()\n",
    "    erp_mask = np.stack(erp_mask)\n",
    "    erp_mask = torch.from_numpy(erp_mask).float()\n",
    "    n_patch = all_combos.shape[0]\n",
    "    \n",
    "    center_point = torch.from_numpy(all_combos).float()  # -180 to 180, -90 to 90\n",
    "    center_point[:, 0] = (center_point[:, 0]) / 360  #0 to 1\n",
    "    center_point[:, 1] = (center_point[:, 1] + 90) / 180  #0 to 1\n",
    "\n",
    "    cp = center_point * 2 - 1\n",
    "    cp[:, 0] = cp[:, 0] * PI\n",
    "    cp[:, 1] = cp[:, 1] * PI_2\n",
    "    cp = cp.unsqueeze(1)\n",
    "\n",
    "    convertedCoord = screen_points * 2 - 1\n",
    "    convertedCoord[:, 0] = convertedCoord[:, 0] * PI\n",
    "    convertedCoord[:, 1] = convertedCoord[:, 1] * PI_2\n",
    "    convertedCoord = convertedCoord * (torch.ones(screen_points.shape, dtype=torch.float32) * FOV)\n",
    "    convertedCoord = convertedCoord.unsqueeze(0).repeat(cp.shape[0], 1, 1)\n",
    "\n",
    "    x = convertedCoord[:, :, 0]\n",
    "    y = convertedCoord[:, :, 1]\n",
    "\n",
    "    rou = torch.sqrt(x ** 2 + y ** 2)\n",
    "    c = torch.atan(rou)\n",
    "    sin_c = torch.sin(c)\n",
    "    cos_c = torch.cos(c)\n",
    "    lat = torch.asin(cos_c * torch.sin(cp[:, :, 1]) + (y * sin_c * torch.cos(cp[:, :, 1])) / rou)\n",
    "    lon = cp[:, :, 0] + torch.atan2(x * sin_c, rou * torch.cos(cp[:, :, 1]) * cos_c - y * torch.sin(cp[:, :, 1]) * sin_c)\n",
    "    lat_new = lat / PI_2\n",
    "    lon_new = lon / PI\n",
    "    lon_new[lon_new > 1] -= 2\n",
    "    lon_new[lon_new<-1] += 2\n",
    "\n",
    "    lon_new = lon_new.view(1, n_patch, height, width).permute(0, 2, 1, 3).contiguous().view(height, n_patch*width)\n",
    "    lat_new = lat_new.view(1, n_patch, height, width).permute(0, 2, 1, 3).contiguous().view(height, n_patch*width)\n",
    "    \n",
    "    grid = torch.stack([lon_new, lat_new], -1)\n",
    "    grid = grid.unsqueeze(0)\n",
    "\n",
    "    return n_patch, grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6c7ba-fe9a-4973-8223-4afa6279db1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21718df3-4885-4051-8dcd-37b8618bb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quaternion_from_euler(e):\n",
    "    \"\"\"\n",
    "    Convert an Euler angle to a quaternion.\n",
    "\n",
    "    Input\n",
    "    :param roll: The roll (rotation around x-axis) angle in radians.\n",
    "    :param pitch: The pitch (rotation around y-axis) angle in radians.\n",
    "    :param yaw: The yaw (rotation around z-axis) angle in radians.\n",
    "\n",
    "    Output\n",
    "    :return qx, qy, qz, qw: The orientation in quaternion [x,y,z,w] format\n",
    "    \"\"\"\n",
    "    roll = e[0]\n",
    "    pitch = e[1]\n",
    "    yaw = e[2]\n",
    "\n",
    "    qx = np.sin(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) - np.cos(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)\n",
    "    qy = np.cos(roll/2) * np.sin(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.cos(pitch/2) * np.sin(yaw/2)\n",
    "    qz = np.cos(roll/2) * np.cos(pitch/2) * np.sin(yaw/2) - np.sin(roll/2) * np.sin(pitch/2) * np.cos(yaw/2)\n",
    "    qw = np.cos(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)\n",
    "\n",
    "    return [qw, qx, qy, qz]\n",
    "\n",
    "def euler_from_quaternion(q):\n",
    "    \"\"\"\n",
    "    Convert a quaternion into euler angles (roll, pitch, yaw)\n",
    "    roll is rotation around x in radians (counterclockwise)\n",
    "    pitch is rotation around y in radians (counterclockwise)\n",
    "    yaw is rotation around z in radians (counterclockwise)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    w = q[0]\n",
    "    x = q[1]\n",
    "    y = q[2]\n",
    "    z = q[3]\n",
    "    \n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    # roll_x = math.atan2(t0, t1) / np.pi * 180 # degrees\n",
    "    roll_x = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    # pitch_y = math.asin(t2) / np.pi * 180\n",
    "    pitch_y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z) \n",
    "    # yaw_z = math.atan2(t3, t4) / np.pi * 180\n",
    "    yaw_z = math.atan2(t3, t4)\n",
    "\n",
    "    return [roll_x, pitch_y, yaw_z] # in radian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe2d07-d70f-410b-9e90-7211fa76a31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1322eb-7491-4fce-9455-7a53e5534a9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Init Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2529dde-b95a-4c2a-9759-6a94897cf841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./ckpt/bevdet4d-r50-depth-cbgs.pth\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "config = \"./configs/bevdet/bevdet4d-r50-depth-cbgs.py\"\n",
    "ckpt = \"./ckpt/bevdet4d-r50-depth-cbgs.pth\"\n",
    "\n",
    "# config = \"./configs/bevdet/bevdet-r50-cbgs.py\"\n",
    "# ckpt = \"./ckpt/bevdet-r50-cbgs.pth\"\n",
    "\n",
    "\"\"\" Init configuration \"\"\"\n",
    "cfg = Config.fromfile(config)\n",
    "cfg = compat_cfg(cfg)\n",
    "\n",
    "if cfg.get('cudnn_benchmark', False): # set cudnn_benchmark\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\"\"\" Init BEVDet model \"\"\"\n",
    "cfg.model.pretrained = None\n",
    "distributed = False\n",
    "if '4D' in cfg.model.type: # video-based or not\n",
    "    cfg.model.align_after_view_transfromation=True\n",
    "cfg.model.train_cfg = None\n",
    "\n",
    "model = build_model(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "fp16_cfg = cfg.get('fp16', None)\n",
    "if fp16_cfg is not None:\n",
    "    wrap_fp16_model(model)\n",
    "checkpoint = load_checkpoint(model, ckpt, map_location=device) # or CPU?\n",
    "model.CLASSES = cfg.class_names\n",
    "\n",
    "\"\"\" Init PoseNet \"\"\"\n",
    "manydepth_model_path = './manydepth/ckpt/KITTI_MR/'\n",
    "\n",
    "pose_enc_dict = torch.load(os.path.join(manydepth_model_path, \"pose_encoder.pth\"), map_location=device)\n",
    "pose_dec_dict = torch.load(os.path.join(manydepth_model_path, \"pose.pth\"), map_location=device)\n",
    "\n",
    "pose_enc = ResnetEncoder(18, False, num_input_images=2)\n",
    "pose_dec = PoseDecoder(pose_enc.num_ch_enc, num_input_features=1, num_frames_to_predict_for=2)\n",
    "\n",
    "pose_enc.load_state_dict(pose_enc_dict, strict=True)\n",
    "pose_dec.load_state_dict(pose_dec_dict, strict=True)\n",
    "\n",
    "\"\"\" Models to GPU memory \"\"\"\n",
    "model.eval()\n",
    "model.to(device)\n",
    "pose_enc.eval()\n",
    "pose_dec.eval()\n",
    "pose_enc.to(device)\n",
    "pose_dec.to(device)\n",
    "\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "\"\"\" Init Tangent Projection Grid \"\"\"\n",
    "num_rows = 1\n",
    "num_cols = [6]\n",
    "phi_centers = [0]\n",
    "\n",
    "# fov 가로/세로 비율과 nuscenes input의 width/height 비율이 같음\n",
    "# 900/1600, 396/704: 1.777777...\n",
    "# 위 비율에 맞춰서 tangent patch size 결정하기\n",
    "# 중요! 704, 256은 aspect ratio가 다름. 원래 코드에서도 704, 396으로 resize하고 추후에 704, 256으로 crop함\n",
    "tangent_h = 396 # 900 # 396\n",
    "tangent_w = 704 # 1600 # 704\n",
    "fov  = [70, 39.375]\n",
    "erp_h, erp_w = 1920, 3840\n",
    "\n",
    "n_patch, grid = createProjectGrid(erp_h, erp_w, tangent_h, tangent_w, num_rows, num_cols, phi_centers, fov)\n",
    "grid = grid.to(device)\n",
    "\n",
    "vis_tangent_h = 900 # visualization resolution\n",
    "vis_tangent_w = 1600\n",
    "\n",
    "n_patch, vis_grid = createProjectGrid(erp_h, erp_w, vis_tangent_h, vis_tangent_w, num_rows, num_cols, phi_centers, fov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d5b7d-bf36-4a63-a791-7fafdb202395",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Init Insta360 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "496fbda8-96b9-4bc2-95e6-6bed358d371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/jeholee/omni3D/data/nuscenes/\n",
      "(1, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Init dataset, data loader, infos \"\"\"\n",
    "cfg.data.test.test_mode = True\n",
    "if cfg.data.test_dataloader.get('samples_per_gpu', 1) > 1:\n",
    "    # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "\n",
    "test_dataloader_default_args = dict(samples_per_gpu=1, workers_per_gpu=1, dist=distributed, shuffle=False)\n",
    "test_loader_cfg = {\n",
    "        **test_dataloader_default_args,\n",
    "        **cfg.data.get('test_dataloader', {})\n",
    "    }\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)\n",
    "\n",
    "infos = dataset.data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2c138a03-f92e-4798-9c29-b902147bbd01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/jeholee/omni3D/BEVDet/mmdet3d/datasets/pipelines/loading.py:347: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  gt_boxes, gt_labels = torch.Tensor(gt_boxes), torch.tensor(gt_labels)\n",
      "/data/home/jeholee/omni3D/BEVDet/mmdet3d/datasets/pipelines/loading.py:347: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  gt_boxes, gt_labels = torch.Tensor(gt_boxes), torch.tensor(gt_labels)\n",
      "/data/home/jeholee/omni3D/BEVDet/mmdet3d/datasets/pipelines/loading.py:347: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  gt_boxes, gt_labels = torch.Tensor(gt_boxes), torch.tensor(gt_labels)\n",
      "/data/home/jeholee/omni3D/BEVDet/mmdet3d/datasets/pipelines/loading.py:347: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  gt_boxes, gt_labels = torch.Tensor(gt_boxes), torch.tensor(gt_labels)\n"
     ]
    }
   ],
   "source": [
    "data_iterator = iter(data_loader)\n",
    "data = next(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e3cfc5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_metas': [DataContainer([[{'flip': False, 'pcd_horizontal_flip': False, 'pcd_vertical_flip': False, 'box_mode_3d': <Box3DMode.LIDAR: 0>, 'box_type_3d': <class 'mmdet3d.core.bbox.structures.lidar_box3d.LiDARInstance3DBoxes'>, 'sample_idx': '30e55a3ec6184d8cb1944b39ba19d622', 'pcd_scale_factor': 1.0, 'pts_filename': '../data/nuscenes/samples/LIDAR_TOP/n015-2018-07-11-11-54-16+0800__LIDAR_TOP__1531281439800013.pcd.bin'}]])],\n",
       " 'points': [DataContainer([[tensor([[-3.1221e+00, -4.4646e-01, -1.8716e+00,  3.7000e+01,  0.0000e+00],\n",
       "          [-3.2848e+00, -4.4473e-01, -1.8656e+00,  7.0000e+00,  1.0000e+00],\n",
       "          [-3.4769e+00, -4.4338e-01, -1.8686e+00,  9.0000e+00,  2.0000e+00],\n",
       "          ...,\n",
       "          [-1.4141e+01, -2.4673e-02,  1.9874e+00,  1.3000e+01,  2.9000e+01],\n",
       "          [ 5.5009e-06, -1.2196e-06, -1.6083e-08,  3.6000e+01,  3.0000e+01],\n",
       "          [-1.0692e+01, -1.3078e-02,  2.0145e+00,  6.0000e+00,  3.1000e+01]])]])],\n",
       " 'img_inputs': [[tensor([[[[[-1.1418, -1.1418, -1.1418,  ...,  1.9920,  2.0092,  1.9407],\n",
       "              [-1.2274, -1.2445, -1.2445,  ...,  1.9920,  2.0434,  2.0092],\n",
       "              [-1.1418, -1.1589, -1.1760,  ...,  2.0092,  2.0605,  2.0434],\n",
       "              ...,\n",
       "              [-1.1075, -1.1075, -1.0904,  ..., -0.1999, -0.2342, -0.1999],\n",
       "              [-1.0733, -1.0733, -1.0733,  ..., -0.1999, -0.1828, -0.1828],\n",
       "              [-1.0219, -1.0219, -1.0390,  ..., -0.2171, -0.1828, -0.1657]],\n",
       "   \n",
       "             [[-1.0728, -1.0728, -1.0203,  ...,  2.0084,  1.9909,  1.8859],\n",
       "              [-1.1078, -1.1254, -1.1254,  ...,  1.9559,  1.9559,  1.8508],\n",
       "              [-1.0203, -1.0378, -1.0553,  ...,  1.9909,  1.9909,  1.9034],\n",
       "              ...,\n",
       "              [-0.8978, -0.8978, -0.8452,  ..., -0.1275, -0.1625, -0.1275],\n",
       "              [-0.9153, -0.9153, -0.8978,  ..., -0.0749, -0.1099, -0.1099],\n",
       "              [-0.8627, -0.8627, -0.8627,  ..., -0.0749, -0.1099, -0.1099]],\n",
       "   \n",
       "             [[-0.9678, -0.9678, -0.9330,  ...,  2.0997,  2.0823,  1.9951],\n",
       "              [-0.9504, -0.9678, -0.9678,  ...,  2.0300,  2.0474,  1.9777],\n",
       "              [-0.8633, -0.8807, -0.8981,  ...,  2.0648,  2.0823,  2.0300],\n",
       "              ...,\n",
       "              [-0.8633, -0.8807, -0.8633,  ...,  0.0082, -0.0267,  0.0082],\n",
       "              [-0.8458, -0.8458, -0.8284,  ...,  0.0431,  0.0256,  0.0256],\n",
       "              [-0.7936, -0.7936, -0.7936,  ...,  0.0431,  0.0256,  0.0256]]],\n",
       "   \n",
       "   \n",
       "            [[[-1.1418, -1.1418, -1.1418,  ...,  1.9920,  2.0092,  1.9407],\n",
       "              [-1.2274, -1.2445, -1.2445,  ...,  1.9920,  2.0434,  2.0092],\n",
       "              [-1.1418, -1.1589, -1.1760,  ...,  2.0092,  2.0605,  2.0434],\n",
       "              ...,\n",
       "              [-1.1075, -1.1075, -1.0904,  ..., -0.1999, -0.2342, -0.1999],\n",
       "              [-1.0733, -1.0733, -1.0733,  ..., -0.1999, -0.1828, -0.1828],\n",
       "              [-1.0219, -1.0219, -1.0390,  ..., -0.2171, -0.1828, -0.1657]],\n",
       "   \n",
       "             [[-1.0728, -1.0728, -1.0203,  ...,  2.0084,  1.9909,  1.8859],\n",
       "              [-1.1078, -1.1254, -1.1254,  ...,  1.9559,  1.9559,  1.8508],\n",
       "              [-1.0203, -1.0378, -1.0553,  ...,  1.9909,  1.9909,  1.9034],\n",
       "              ...,\n",
       "              [-0.8978, -0.8978, -0.8452,  ..., -0.1275, -0.1625, -0.1275],\n",
       "              [-0.9153, -0.9153, -0.8978,  ..., -0.0749, -0.1099, -0.1099],\n",
       "              [-0.8627, -0.8627, -0.8627,  ..., -0.0749, -0.1099, -0.1099]],\n",
       "   \n",
       "             [[-0.9678, -0.9678, -0.9330,  ...,  2.0997,  2.0823,  1.9951],\n",
       "              [-0.9504, -0.9678, -0.9678,  ...,  2.0300,  2.0474,  1.9777],\n",
       "              [-0.8633, -0.8807, -0.8981,  ...,  2.0648,  2.0823,  2.0300],\n",
       "              ...,\n",
       "              [-0.8633, -0.8807, -0.8633,  ...,  0.0082, -0.0267,  0.0082],\n",
       "              [-0.8458, -0.8458, -0.8284,  ...,  0.0431,  0.0256,  0.0256],\n",
       "              [-0.7936, -0.7936, -0.7936,  ...,  0.0431,  0.0256,  0.0256]]],\n",
       "   \n",
       "   \n",
       "            [[[-1.1418, -1.1418, -1.1418,  ...,  1.9920,  2.0092,  1.9407],\n",
       "              [-1.2274, -1.2445, -1.2445,  ...,  1.9920,  2.0434,  2.0092],\n",
       "              [-1.1418, -1.1589, -1.1760,  ...,  2.0092,  2.0605,  2.0434],\n",
       "              ...,\n",
       "              [-1.1075, -1.1075, -1.0904,  ..., -0.1999, -0.2342, -0.1999],\n",
       "              [-1.0733, -1.0733, -1.0733,  ..., -0.1999, -0.1828, -0.1828],\n",
       "              [-1.0219, -1.0219, -1.0390,  ..., -0.2171, -0.1828, -0.1657]],\n",
       "   \n",
       "             [[-1.0728, -1.0728, -1.0203,  ...,  2.0084,  1.9909,  1.8859],\n",
       "              [-1.1078, -1.1254, -1.1254,  ...,  1.9559,  1.9559,  1.8508],\n",
       "              [-1.0203, -1.0378, -1.0553,  ...,  1.9909,  1.9909,  1.9034],\n",
       "              ...,\n",
       "              [-0.8978, -0.8978, -0.8452,  ..., -0.1275, -0.1625, -0.1275],\n",
       "              [-0.9153, -0.9153, -0.8978,  ..., -0.0749, -0.1099, -0.1099],\n",
       "              [-0.8627, -0.8627, -0.8627,  ..., -0.0749, -0.1099, -0.1099]],\n",
       "   \n",
       "             [[-0.9678, -0.9678, -0.9330,  ...,  2.0997,  2.0823,  1.9951],\n",
       "              [-0.9504, -0.9678, -0.9678,  ...,  2.0300,  2.0474,  1.9777],\n",
       "              [-0.8633, -0.8807, -0.8981,  ...,  2.0648,  2.0823,  2.0300],\n",
       "              ...,\n",
       "              [-0.8633, -0.8807, -0.8633,  ...,  0.0082, -0.0267,  0.0082],\n",
       "              [-0.8458, -0.8458, -0.8284,  ...,  0.0431,  0.0256,  0.0256],\n",
       "              [-0.7936, -0.7936, -0.7936,  ...,  0.0431,  0.0256,  0.0256]]],\n",
       "   \n",
       "   \n",
       "            ...,\n",
       "   \n",
       "   \n",
       "            [[[-1.1589, -1.1418, -1.2788,  ...,  0.7419,  0.7419,  0.7077],\n",
       "              [-1.1760, -1.1932, -1.3130,  ...,  0.6563,  0.6734,  0.6906],\n",
       "              [-1.1932, -1.2103, -1.3302,  ...,  0.5707,  0.6049,  0.6734],\n",
       "              ...,\n",
       "              [-1.6384, -1.5870, -1.5870,  ..., -1.0904, -1.0904, -1.1247],\n",
       "              [-1.6213, -1.5699, -1.6555,  ..., -1.1247, -1.1075, -1.1247],\n",
       "              [-1.7240, -1.6727, -1.7583,  ..., -1.1075, -1.0904, -1.0904]],\n",
       "   \n",
       "             [[-1.0903, -1.0903, -1.2129,  ...,  0.8704,  0.8704,  0.8354],\n",
       "              [-1.1254, -1.1429, -1.2129,  ...,  0.7829,  0.8004,  0.8179],\n",
       "              [-1.1429, -1.1604, -1.2304,  ...,  0.6954,  0.7304,  0.8004],\n",
       "              ...,\n",
       "              [-1.4055, -1.3529, -1.3529,  ..., -0.8978, -0.8978, -0.9328],\n",
       "              [-1.4405, -1.3354, -1.3704,  ..., -0.9328, -0.9153, -0.9328],\n",
       "              [-1.5630, -1.4230, -1.4405,  ..., -0.9153, -0.8803, -0.8803]],\n",
       "   \n",
       "             [[-1.0201, -1.0201, -1.1247,  ...,  1.0191,  1.0191,  0.9842],\n",
       "              [-0.9678, -1.0027, -1.1247,  ...,  0.9319,  0.9494,  0.9668],\n",
       "              [-0.9853, -1.0201, -1.1421,  ...,  0.8448,  0.8797,  0.9494],\n",
       "              ...,\n",
       "              [-1.1944, -1.1247, -1.1421,  ..., -0.6890, -0.6890, -0.7238],\n",
       "              [-1.2816, -1.1596, -1.1596,  ..., -0.7587, -0.7587, -0.7761],\n",
       "              [-1.4384, -1.2641, -1.2467,  ..., -0.7238, -0.7413, -0.7413]]],\n",
       "   \n",
       "   \n",
       "            [[[-1.1589, -1.1418, -1.2788,  ...,  0.7419,  0.7419,  0.7077],\n",
       "              [-1.1760, -1.1932, -1.3130,  ...,  0.6563,  0.6734,  0.6906],\n",
       "              [-1.1932, -1.2103, -1.3302,  ...,  0.5707,  0.6049,  0.6734],\n",
       "              ...,\n",
       "              [-1.6384, -1.5870, -1.5870,  ..., -1.0904, -1.0904, -1.1247],\n",
       "              [-1.6213, -1.5699, -1.6555,  ..., -1.1247, -1.1075, -1.1247],\n",
       "              [-1.7240, -1.6727, -1.7583,  ..., -1.1075, -1.0904, -1.0904]],\n",
       "   \n",
       "             [[-1.0903, -1.0903, -1.2129,  ...,  0.8704,  0.8704,  0.8354],\n",
       "              [-1.1254, -1.1429, -1.2129,  ...,  0.7829,  0.8004,  0.8179],\n",
       "              [-1.1429, -1.1604, -1.2304,  ...,  0.6954,  0.7304,  0.8004],\n",
       "              ...,\n",
       "              [-1.4055, -1.3529, -1.3529,  ..., -0.8978, -0.8978, -0.9328],\n",
       "              [-1.4405, -1.3354, -1.3704,  ..., -0.9328, -0.9153, -0.9328],\n",
       "              [-1.5630, -1.4230, -1.4405,  ..., -0.9153, -0.8803, -0.8803]],\n",
       "   \n",
       "             [[-1.0201, -1.0201, -1.1247,  ...,  1.0191,  1.0191,  0.9842],\n",
       "              [-0.9678, -1.0027, -1.1247,  ...,  0.9319,  0.9494,  0.9668],\n",
       "              [-0.9853, -1.0201, -1.1421,  ...,  0.8448,  0.8797,  0.9494],\n",
       "              ...,\n",
       "              [-1.1944, -1.1247, -1.1421,  ..., -0.6890, -0.6890, -0.7238],\n",
       "              [-1.2816, -1.1596, -1.1596,  ..., -0.7587, -0.7587, -0.7761],\n",
       "              [-1.4384, -1.2641, -1.2467,  ..., -0.7238, -0.7413, -0.7413]]],\n",
       "   \n",
       "   \n",
       "            [[[-1.1589, -1.1418, -1.2788,  ...,  0.7419,  0.7419,  0.7077],\n",
       "              [-1.1760, -1.1932, -1.3130,  ...,  0.6563,  0.6734,  0.6906],\n",
       "              [-1.1932, -1.2103, -1.3302,  ...,  0.5707,  0.6049,  0.6734],\n",
       "              ...,\n",
       "              [-1.6384, -1.5870, -1.5870,  ..., -1.0904, -1.0904, -1.1247],\n",
       "              [-1.6213, -1.5699, -1.6555,  ..., -1.1247, -1.1075, -1.1247],\n",
       "              [-1.7240, -1.6727, -1.7583,  ..., -1.1075, -1.0904, -1.0904]],\n",
       "   \n",
       "             [[-1.0903, -1.0903, -1.2129,  ...,  0.8704,  0.8704,  0.8354],\n",
       "              [-1.1254, -1.1429, -1.2129,  ...,  0.7829,  0.8004,  0.8179],\n",
       "              [-1.1429, -1.1604, -1.2304,  ...,  0.6954,  0.7304,  0.8004],\n",
       "              ...,\n",
       "              [-1.4055, -1.3529, -1.3529,  ..., -0.8978, -0.8978, -0.9328],\n",
       "              [-1.4405, -1.3354, -1.3704,  ..., -0.9328, -0.9153, -0.9328],\n",
       "              [-1.5630, -1.4230, -1.4405,  ..., -0.9153, -0.8803, -0.8803]],\n",
       "   \n",
       "             [[-1.0201, -1.0201, -1.1247,  ...,  1.0191,  1.0191,  0.9842],\n",
       "              [-0.9678, -1.0027, -1.1247,  ...,  0.9319,  0.9494,  0.9668],\n",
       "              [-0.9853, -1.0201, -1.1421,  ...,  0.8448,  0.8797,  0.9494],\n",
       "              ...,\n",
       "              [-1.1944, -1.1247, -1.1421,  ..., -0.6890, -0.6890, -0.7238],\n",
       "              [-1.2816, -1.1596, -1.1596,  ..., -0.7587, -0.7587, -0.7761],\n",
       "              [-1.4384, -1.2641, -1.2467,  ..., -0.7238, -0.7413, -0.7413]]]]]),\n",
       "   tensor([[[[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]],\n",
       "   \n",
       "            [[ 8.2045e-01, -3.8220e-04,  5.7172e-01],\n",
       "             [-5.7172e-01,  3.2381e-03,  8.2044e-01],\n",
       "             [-2.1649e-03, -9.9999e-01,  2.4382e-03]],\n",
       "   \n",
       "            [[ 5.6849e-03, -5.6367e-03,  9.9997e-01],\n",
       "             [-9.9998e-01, -8.3712e-04,  5.6802e-03],\n",
       "             [ 8.0507e-04, -9.9998e-01, -5.6413e-03]],\n",
       "   \n",
       "            [[-8.3262e-01,  9.3526e-06,  5.5384e-01],\n",
       "             [-5.5377e-01,  1.6347e-02, -8.3251e-01],\n",
       "             [-9.0613e-03, -9.9987e-01, -1.3605e-02]],\n",
       "   \n",
       "            [[ 9.4674e-01,  8.6773e-03, -3.2189e-01],\n",
       "             [ 3.2199e-01, -1.4095e-02,  9.4664e-01],\n",
       "             [ 3.6770e-03, -9.9986e-01, -1.6139e-02]],\n",
       "   \n",
       "            [[ 2.8152e-04, -1.6744e-02, -9.9986e-01],\n",
       "             [ 9.9999e-01, -4.0623e-03,  3.4970e-04],\n",
       "             [-4.0676e-03, -9.9985e-01,  1.6743e-02]],\n",
       "   \n",
       "            [[-9.3517e-01,  1.5892e-02, -3.5384e-01],\n",
       "             [ 3.5404e-01,  1.1342e-02, -9.3516e-01],\n",
       "             [-1.0848e-02, -9.9981e-01, -1.6233e-02]]]]),\n",
       "   tensor([[[ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651],\n",
       "            [ 1.4542,  0.4944,  1.5079],\n",
       "            [ 1.7008,  0.0159,  1.5110],\n",
       "            [ 1.6235, -0.4932,  1.4972],\n",
       "            [ 1.3604,  0.4866,  1.5971],\n",
       "            [ 0.2612,  0.0022,  1.5835],\n",
       "            [ 1.1574, -0.4807,  1.5651]]]),\n",
       "   tensor([[[[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2726e+03, 0.0000e+00, 8.2662e+02],\n",
       "             [0.0000e+00, 1.2726e+03, 4.7975e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2664e+03, 0.0000e+00, 8.1627e+02],\n",
       "             [0.0000e+00, 1.2664e+03, 4.9151e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2608e+03, 0.0000e+00, 8.0797e+02],\n",
       "             [0.0000e+00, 1.2608e+03, 4.9533e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2567e+03, 0.0000e+00, 7.9211e+02],\n",
       "             [0.0000e+00, 1.2567e+03, 4.9278e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[8.0922e+02, 0.0000e+00, 8.2922e+02],\n",
       "             [0.0000e+00, 8.0922e+02, 4.8178e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
       "   \n",
       "            [[1.2595e+03, 0.0000e+00, 8.0725e+02],\n",
       "             [0.0000e+00, 1.2595e+03, 5.0120e+02],\n",
       "             [0.0000e+00, 0.0000e+00, 1.0000e+00]]]]),\n",
       "   tensor([[[[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]],\n",
       "   \n",
       "            [[0.4400, 0.0000, 0.0000],\n",
       "             [0.0000, 0.4400, 0.0000],\n",
       "             [0.0000, 0.0000, 1.0000]]]]),\n",
       "   tensor([[[   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.],\n",
       "            [   0., -140.,    0.]]]),\n",
       "   tensor([[[1., 0., 0.],\n",
       "            [0., 1., 0.],\n",
       "            [0., 0., 1.]]])]]}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1e783865-5a9d-40d4-98db-c46e813a562e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_idx = 8\n",
    "# data_iterator = iter(data_loader)\n",
    "\n",
    "# cnt = -1\n",
    "# while cnt < sample_idx:\n",
    "#     data = next(data_iterator)\n",
    "#     cnt += 1\n",
    "# print(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "00d26fec-64d8-4b6a-8b57-57368d277218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_erp_img(fname):\n",
    "    # load images\n",
    "    print(f\"Load erp image: {fname}\")\n",
    "    erp_img = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    erp_img = erp_img.astype(np.float32) / 255\n",
    "    erp_img = np.transpose(erp_img, [2, 0, 1]) # permutation, 세 번째 axis가 첫 번째 axis로\n",
    "    erp_img = torch.from_numpy(erp_img) # Create Tensor from numpy array\n",
    "    erp_img = erp_img.unsqueeze(0) # Increase Tensor dimension by 1\n",
    "    return erp_img\n",
    "\n",
    "img_conf = dict(img_mean=[123.675, 116.28, 103.53],\n",
    "                img_std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True)\n",
    "\n",
    "tangent_intrinsics = {'CAM_FRONT_LEFT': [[1.31669199e+03, 0.00000000e+00, 7.71567974e+02], # Tangent location 0 (leftmost)\n",
    "                                         [0.00000000e+00, 1.30594375e+03, 4.27529182e+02],\n",
    "                                         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]],\n",
    "                      'CAM_FRONT': [[1.32277551e+03, 0.00000000e+00, 7.56801337e+02], # Tangent location 1\n",
    "                                    [0.00000000e+00, 1.31076362e+03, 4.17111552e+02],\n",
    "                                    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]],\n",
    "                      'CAM_FRONT_RIGHT': [[1.31303854e+03, 0.00000000e+00, 7.16879740e+02], # Tangent location 2\n",
    "                                          [0.00000000e+00, 1.30008012e+03, 4.21897818e+02],\n",
    "                                          [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]],\n",
    "                      'CAM_BACK_LEFT': [[1.31538668e+03, 0.00000000e+00, 7.62655552e+02], # Tangent location 3\n",
    "                                        [0.00000000e+00, 1.30582175e+03, 4.21392564e+02],\n",
    "                                        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]],\n",
    "                      'CAM_BACK': [[1.37645753e+03, 0.00000000e+00, 7.33078005e+02], # Tangent location 4\n",
    "                                   [0.00000000e+00, 1.36126888e+03, 4.13681559e+02],\n",
    "                                   [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]],\n",
    "                      'CAM_BACK_RIGHT': [[1.33525055e+03, 0.00000000e+00, 7.02715248e+02], # Tangent location 5\n",
    "                                         [0.00000000e+00, 1.32071237e+03, 4.12790092e+02],\n",
    "                                         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]}\n",
    "\n",
    "tangent_intrinsics_list = []\n",
    "for cam in cfg.data_config['cams']:\n",
    "    tangent_intrinsics_list.append(torch.Tensor(tangent_intrinsics[cam]))\n",
    "tangent_intrinsics = torch.stack(tangent_intrinsics_list)\n",
    "\n",
    "# sensor2ego rotation 변경!\n",
    "sensor2ego_rot_eulers = {'CAM_FRONT_LEFT': [-90.0, 0.0, 60.0],\n",
    "                         'CAM_FRONT': [-90.0, 0.0, 0.0],\n",
    "                         'CAM_FRONT_RIGHT': [-90.0, 0.0, -60.0],\n",
    "                         'CAM_BACK_LEFT': [-90.0, 0.0, 240.0],\n",
    "                         'CAM_BACK': [-90.0, 0.0, 180.0],\n",
    "                         'CAM_BACK_RIGHT': [-90.0, 0.0, 120.0]}\n",
    "\n",
    "# x, y 좌표는 ego sensor와 virtual tangent sensor 간에 차이가 없는게 맞음\n",
    "# 그럼 왜 z는?\n",
    "# sensor2ego_trans = [0.0, 0.0, 0.0]\n",
    "sensor2ego_trans = [0.0, 0.0, 1.5]\n",
    "\n",
    "# sensor2ego matrix\n",
    "sensor2ego_mats = []\n",
    "for cam in cfg.data_config['cams']:\n",
    "    sensor2ego_degrees = sensor2ego_rot_eulers[cam]\n",
    "    sensor2ego_radians = [degree * np.pi / 180 for degree in sensor2ego_degrees]\n",
    "    sensor2ego_q = Quaternion(get_quaternion_from_euler(sensor2ego_radians))\n",
    "    w, x, y, z = sensor2ego_q\n",
    "\n",
    "    sensor2ego_rot = torch.Tensor(Quaternion(w, x, y, z).rotation_matrix)\n",
    "    sensor2ego_tran = torch.Tensor(sensor2ego_trans)\n",
    "\n",
    "    sensor2ego = sensor2ego_rot.new_zeros((4, 4))\n",
    "    sensor2ego[3, 3] = 1\n",
    "    sensor2ego[:3, :3] = sensor2ego_rot\n",
    "    sensor2ego[:3, -1] = sensor2ego_tran\n",
    "    \n",
    "    sensor2ego_mats.append(sensor2ego)\n",
    "sensor2ego_mats = torch.stack(sensor2ego_mats)\n",
    "\n",
    "# calibrated_sensors = []\n",
    "# for cam in cfg.data_config['cams']:\n",
    "\n",
    "# ego2global_rotation = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "# ego2global_translation = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "scene_dir = \"scene_3/\"\n",
    "erp_img_root = \"../data/daejeon_road_outdoor/erp_images_2hz/\"\n",
    "# erp_img_root = \"../data/daejeon_road_outdoor/erp_images_10hz/\"\n",
    "\n",
    "erp_files = []\n",
    "for filename in os.listdir(erp_img_root + scene_dir):\n",
    "    erp_files.append(os.path.join(erp_img_root, scene_dir, filename))\n",
    "\n",
    "with torch.no_grad():\n",
    "    sensor2ego_mats = sensor2ego_mats.to(device)\n",
    "    tangent_intrinsics = tangent_intrinsics.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "313af129-5c76-499c-af1c-435a602bb600",
   "metadata": {},
   "source": [
    "#### vqueue\n",
    "- sample_idx\n",
    "- tangent patches\n",
    "- sensor2sensor (직전 frame 대비 pose 변화)\n",
    "- ego pose (현재 pose -> 누적해서 계산해야함)\n",
    "\n",
    "#### TODO\n",
    "- 실제 환경에서 video frame 하나씩 받으면서 처리하는 것처럼 구현\n",
    "- 여러 tensor들을 언제 GPU memory에 올리고 언제 free시킬지 => memory management 구현해야함\n",
    "- Video queue의 size는 좀 크게 두고, SOLOFusion의 long-term fusion window size를 다이내믹하게 조절하는 방법?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "11e2d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = cfg.multi_adj_frame_id_cfg[1]\n",
    "vqueue = list()\n",
    "\n",
    "sequential = True # Whether to use BEVDet4D or BEVDet\n",
    "window_size = 9\n",
    "ego_cam = 'CAM_FRONT'\n",
    "\n",
    "sample_idx = -1\n",
    "\n",
    "# scene 3\n",
    "# range(39, 80) 빠른 직진 (매우 많이 이동함)\n",
    "# range(199, 400) 10Hz\n",
    "# 10Hz vs 2Hz 비교\n",
    "#   - 2Hz: range(39, 41)\n",
    "#   - 10Hz: range(199, 201)\n",
    "\n",
    "# scene 2\n",
    "# range(0, 15) 2Hz\n",
    "# range(0, 61) 10Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "eaf6cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load erp image: ../data/daejeon_road_outdoor/erp_images_2hz/scene_3/frame_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "# next data\n",
    "sample_idx += 1\n",
    "\n",
    "H, W = cfg.data_config['src_size']\n",
    "fH, fW = cfg.data_config['input_size'] # 256, 704\n",
    "newH, newW = tangent_h, tangent_w\n",
    "crop_h = int((1 - np.mean(cfg.data_config['crop_h'])) * newH) - fH\n",
    "crop_w = int(max(0, newW - fW) / 2)\n",
    "tangent_crop = (crop_w, crop_h, crop_w + fW, crop_h + fH)\n",
    "\n",
    "# post-homography transformation\n",
    "post_rot = torch.eye(2)\n",
    "post_tran = torch.zeros(2)\n",
    "\n",
    "resize = float(fW) / float(W)\n",
    "resize += cfg.data_config.get('resize_test', 0.0)\n",
    "rotate = 0\n",
    "\n",
    "post_rot *= resize\n",
    "post_tran -= torch.Tensor(tangent_crop[:2])\n",
    "\n",
    "rot_h = rotate / 180 * np.pi\n",
    "A = torch.Tensor([[np.cos(rot_h), np.sin(rot_h)], [-np.sin(rot_h), np.cos(rot_h)]])\n",
    "b = torch.Tensor([tangent_crop[2] - tangent_crop[0], tangent_crop[3] - tangent_crop[1]]) / 2\n",
    "b = A.matmul(-b) + b\n",
    "\n",
    "post_rot2 = A.matmul(post_rot)\n",
    "post_tran2 = A.matmul(post_tran) + b\n",
    "post_tran = torch.zeros(3) # for convenience, make augmentation matrices 3x3\n",
    "post_rot = torch.eye(3)\n",
    "post_tran[:2] = post_tran2\n",
    "post_rot[:2, :2] = post_rot2\n",
    "\n",
    "campose_input_crop = (0, 168, 640, 360)\n",
    "\n",
    "with torch.no_grad():\n",
    "    cur_erp_img = get_erp_img(erp_files[sample_idx]) # current erp image\n",
    "    \n",
    "    \"\"\" 1. 현재 frame (sample_idx)에 대한 정보들 계산 후 큐 저장 \"\"\"\n",
    "    cur_data = {'sample_idx': sample_idx}\n",
    "    cur_erp_img = cur_erp_img.to(device)\n",
    "\n",
    "    # Collect tangent patches of erp image\n",
    "    persp = F.grid_sample(cur_erp_img, grid, mode='bilinear', padding_mode='zeros', align_corners=True)\n",
    "    persp_reshape = F.unfold(persp, kernel_size=(tangent_h, tangent_w), stride=(tangent_h, tangent_w))\n",
    "    persp_seq = persp_reshape.reshape(1, 3, tangent_h, tangent_w, n_patch)\n",
    "\n",
    "    patches = list()\n",
    "    pose_inputs = list()\n",
    "    for cam_idx in range(len(cfg.data_config['cams'])):\n",
    "        patch = persp_seq[0, :, :, :, cam_idx]\n",
    "\n",
    "        # Color change\n",
    "        patch = patch.permute(1, 2, 0).cpu().numpy()\n",
    "        patch = patch * 255\n",
    "        patch = patch[:,:,[2,1,0]].astype(np.uint8)\n",
    "\n",
    "        patch = transforms.ToPILImage()(patch) # time (ms): 5.7\n",
    "\n",
    "        # Camera pose est. input\n",
    "        campose_input = patch.crop(campose_input_crop)\n",
    "        campose_input = transforms.ToTensor()(campose_input).unsqueeze(0)\n",
    "        campose_input = campose_input.to(device)\n",
    "        pose_inputs.append(campose_input)\n",
    "\n",
    "        # image transformation (resize, crop, flip, rotate, ...)\n",
    "        # Resizing images is already done in tangent projection, only cropping is applied\n",
    "        patch = patch.crop(tangent_crop)\n",
    "        patch = mmcv.imnormalize(np.array(patch),\n",
    "                                np.array(img_conf['img_mean'], np.float32), # TODO check: img_mean, img_std?\n",
    "                                np.array(img_conf['img_std'], np.float32),\n",
    "                                img_conf['to_rgb']) # time (ms):  5.79\n",
    "        # patch = torch.from_numpy(patch).permute(2, 0, 1) # BEVDepth 버전\n",
    "        patch = torch.tensor(patch).float().permute(2, 0, 1).contiguous() # BEVDet 버전 - 결과는 같음, 시간차이?\n",
    "        patch = patch.to(device) # time (ms): 1.20\n",
    "        patches.append(patch)\n",
    "\n",
    "    cur_data['patches'] = patches\n",
    "    cur_data['pose_inputs'] = pose_inputs\n",
    "\n",
    "    # Camera pose\n",
    "    if len(vqueue) > 0:\n",
    "        # Relative camera pose estimation btw. last frame and current frame\n",
    "        prev_data = vqueue[-1] # Last frame\n",
    "        prev_pose_inputs = prev_data['pose_inputs']\n",
    "        sweep_pose_inputs = [torch.stack(pose_inputs), torch.stack(prev_pose_inputs)]\n",
    "        \n",
    "        \"\"\" TODO source 및 target의 관계가 어떻게 되는지, invert의 유무 어떻게 설정해야 하는지 명확히 \"\"\"\n",
    "        # Transformation matrix for previous camera (sensor) frame to current camera frame\n",
    "        sensor2sensor_mats = list()\n",
    "        for cam_idx in range(len(cfg.data_config['cams'])):\n",
    "            source_image = sweep_pose_inputs[1][cam_idx] # source: previous frame\n",
    "            target_image = sweep_pose_inputs[0][cam_idx] # target: current frame need to be pose estimated\n",
    "            pose_inputs = [source_image, target_image]\n",
    "            pose_inputs = [pose_enc(torch.cat(pose_inputs, 1))]\n",
    "            axisangle, translation = pose_dec(pose_inputs)\n",
    "            # print(\"CAM\", cfg.data_config['cams'][cam_idx])\n",
    "            # print(\"pose axis angle\", axisangle)\n",
    "            pose = transformation_from_parameters(axisangle[:, 0], translation[:, 0], invert=False) # TODO invert?\n",
    "            # print(f\"{cfg.data_config['cams'][cam_idx]}'s relative pose transformation: \\n{pose}\")\n",
    "            sensor2sensor_mats.append(pose)\n",
    "\n",
    "        # Calculate ego2global (ego pose) of the current frame\n",
    "        \n",
    "        # 1. sensor2sensor에서 먼저 평균을 구한 뒤 cur_ego2global 구하기\n",
    "        # sensor2sensor_mat_sum = sensor2sensor_mats[0].new_zeros((4, 4))\n",
    "        # for mat in sensor2sensor_mats:\n",
    "        #     sensor2sensor_mat_sum += mat\n",
    "        # prev_sensor2cur_sensor = sensor2sensor_mat_sum / len(sensor2sensor_mats) # average\n",
    "        # cur_sensor2prev_sensor = prev_sensor2cur_sensor.inverse()\n",
    "        # prev_ego2global = prev_data['ego2global'].to(device)\n",
    "        # cur_ego2global = prev_ego2global @ cur_sensor2prev_sensor\n",
    "            \n",
    "        # 2. 각 cam 마다 cur_ego2global 구하고 평균 내기\n",
    "        ego2global_sum = torch.zeros(4, 4).to(device)\n",
    "        prev_ego2global = prev_data['ego2global'].to(device)\n",
    "        for cam_idx, cam in enumerate(cfg.data_config['cams']):\n",
    "            sensor2ego_mat = sensor2ego_mats[cam_idx]\n",
    "            cur_sensor2prev_sensor = sensor2sensor_mats[cam_idx].inverse().to(device)\n",
    "            ego2sensor_mat = sensor2ego_mat.inverse().to(device)\n",
    "\n",
    "            cam_ego2global = prev_ego2global @ sensor2ego_mat @ cur_sensor2prev_sensor @ ego2sensor_mat\n",
    "            ego2global_sum += cam_ego2global\n",
    "        cur_ego2global = ego2global_sum / len(cfg.data_config['cams'])\n",
    "        \n",
    "        # 3. CAM_FRONT_RIGHT만 사용하여 cur_ego2global 구하기\n",
    "        # prev_ego2global = prev_data['ego2global'].to(device)\n",
    "        # sensor2ego_mat = sensor2ego_mats[\"CAM_FRONT_RIGHT\"].to(device)\n",
    "        # cur_sensor2prev_sensor = sensor2sensor_mats[2].inverse().to(device)\n",
    "        # # print(cur_sensor2prev_sensor)\n",
    "        # ego2sensor_mat = sensor2ego_mat.inverse().to(device)\n",
    "        # cur_ego2global = prev_ego2global @ sensor2ego_mat @ cur_sensor2prev_sensor @ ego2sensor_mat\n",
    "\n",
    "        # print(f\"\\n Previous ego2global: \\n{prev_ego2global}\")\n",
    "        # print(f\"\\n Current ego2global: \\n{cur_ego2global}\")\n",
    "\n",
    "    else: # Initial step\n",
    "        # initial ego pose matrix\n",
    "        w, x, y, z = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "        ego2global_rot = torch.Tensor(Quaternion(w, x, y, z).rotation_matrix)\n",
    "        ego2global_tran = torch.Tensor(np.array([0.0, 0.0, 0.0]))\n",
    "        cur_ego2global = ego2global_rot.new_zeros((4, 4))\n",
    "        cur_ego2global[3, 3] = 1\n",
    "        cur_ego2global[:3, :3] = ego2global_rot\n",
    "        cur_ego2global[:3, -1] = ego2global_tran\n",
    "\n",
    "    cur_data['ego2global'] = cur_ego2global.to(device)\n",
    "    \n",
    "    # TODO: tangent projection setting에 따라 달라질 수 있음\n",
    "    cur_data['sensor2ego_mats'] = sensor2ego_mats\n",
    "    cur_data['intrinsics'] = tangent_intrinsics\n",
    "    \n",
    "    # cur_data 업데이트 한 뒤 vqueue에 저장\n",
    "    vqueue.append(cur_data) # vqueue item => {'sample_idx', 'patches', 'pose_inputs', 'ego2global', 'sensor2ego_mats', 'intrinsics'}\n",
    "    \n",
    "    \"\"\" 2. BEVDet4D input 준비 \"\"\"\n",
    "\n",
    "    imgs = []\n",
    "    rots = []\n",
    "    trans = []\n",
    "    intrins = []\n",
    "    post_rots = []\n",
    "    post_trans = []\n",
    "    \n",
    "    if sequential: # Collect input data of current sliding window (total 9 frames in default setting)\n",
    "        target_indexes = []\n",
    "        for select_id in range(0, window_size):\n",
    "            target_indexes.append(max(cur_data['sample_idx'] - select_id, 0))\n",
    "        \n",
    "        # Collect images ([[CAM_FRONT_LEFTs], [CAM_FRONTs], [...], ...])\n",
    "        for cam_idx, cam_name in enumerate(cfg.data_config['cams']):\n",
    "            for target_idx in target_indexes:\n",
    "                imgs.append(vqueue[target_idx]['patches'][cam_idx])    \n",
    "                \n",
    "        # Collect sensor information ([[current info], [current-1 info], [current-2 info], ...])\n",
    "        key_vdata = vqueue[target_indexes[0]]\n",
    "        for target_idx in target_indexes: # iter sweep data\n",
    "            sweep_vdata = vqueue[target_idx]\n",
    "            for cam_idx, cam_name in enumerate(cfg.data_config['cams']):\n",
    "                # sensor2keyego\n",
    "                sweepsensor2sweepego_mat = sweep_vdata['sensor2ego_mats'][cam_idx]\n",
    "                sweepego2global_mat = sweep_vdata['ego2global']\n",
    "                global2keyego_mat = key_vdata['ego2global'].inverse()\n",
    "                sweepsensor2keyego_mat = global2keyego_mat @ sweepego2global_mat @ sweepsensor2sweepego_mat\n",
    "                rot = sweepsensor2keyego_mat[:3, :3]\n",
    "                tran = sweepsensor2keyego_mat[:3, 3]\n",
    "                \n",
    "                rots.append(rot)\n",
    "                trans.append(tran)\n",
    "                post_trans.append(post_tran)\n",
    "                post_rots.append(post_rot)\n",
    "                intrins.append(sweep_vdata['intrinsics'][cam_idx])\n",
    "        \n",
    "    else:\n",
    "        for cam_idx, cam_name in enumerate(cfg.data_config['cams']):\n",
    "            imgs.append(cur_data['patches'][cam_idx])\n",
    "            rots.append(cur_data['sensor2ego_mats'][cam_idx][:3, :3])\n",
    "            trans.append(cur_data['sensor2ego_mats'][cam_idx][:3, -1])\n",
    "            post_rots.append(post_rot)\n",
    "            post_trans.append(post_tran)\n",
    "            intrins.append(cur_data['intrinsics'][cam_idx])\n",
    "    \n",
    "    # 취합\n",
    "    imgs = torch.stack(imgs)\n",
    "    rots = torch.stack(rots)\n",
    "    trans = torch.stack(trans)\n",
    "    post_rots = torch.stack(post_rots)\n",
    "    post_trans = torch.stack(post_trans)\n",
    "    intrins = torch.stack(intrins)\n",
    "    \n",
    "    img_inputs = (imgs, rots, trans, intrins, post_rots, post_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d115eb94-8f04-4b4f-a3cb-c144e2838df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "\n",
      "tensor([[ 1.0000e+00, -9.9789e-03,  2.5393e-03, -3.6686e-03],\n",
      "        [ 9.9798e-03,  1.0000e+00,  3.3222e-04, -6.2647e-07],\n",
      "        [-2.5354e-03, -2.9973e-04,  9.9999e-01, -7.0552e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9996e-01, -1.8256e-02,  4.9800e-03, -6.6262e-03],\n",
      "        [ 1.8255e-02,  9.9997e-01,  9.0567e-04, -4.5917e-04],\n",
      "        [-4.9831e-03, -8.0245e-04,  9.9999e-01, -9.9242e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9986e-01, -2.6605e-02,  7.4740e-03, -9.7700e-03],\n",
      "        [ 2.6599e-02,  9.9988e-01,  1.7297e-03, -1.2488e-03],\n",
      "        [-7.4954e-03, -1.5127e-03,  9.9998e-01, -1.4271e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9977e-01, -3.5771e-02,  1.0249e-02, -1.3413e-02],\n",
      "        [ 3.5750e-02,  9.9979e-01,  2.0588e-03, -1.4414e-03],\n",
      "        [-1.0288e-02, -1.6663e-03,  9.9997e-01, -1.7210e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9955e-01, -4.8114e-02,  1.2622e-02, -1.7082e-02],\n",
      "        [ 4.8077e-02,  9.9957e-01,  2.3816e-03, -1.3620e-03],\n",
      "        [-1.2689e-02, -1.7443e-03,  9.9997e-01, -1.7518e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9866e-01, -6.4361e-02,  1.5070e-02, -2.1265e-02],\n",
      "        [ 6.4290e-02,  9.9869e-01,  2.8767e-03, -2.3545e-03],\n",
      "        [-1.5189e-02, -1.8723e-03,  9.9996e-01, -1.0669e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9722e-01, -8.2909e-02,  1.7447e-02, -2.5781e-02],\n",
      "        [ 8.2829e-02,  9.9726e-01,  3.8667e-03, -4.0530e-03],\n",
      "        [-1.7674e-02, -2.3801e-03,  9.9996e-01, -8.0665e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n",
      "tensor([[ 9.9517e-01, -1.0376e-01,  1.9921e-02, -3.0699e-02],\n",
      "        [ 1.0368e-01,  9.9521e-01,  4.5113e-03, -5.3010e-03],\n",
      "        [-2.0247e-02, -2.3938e-03,  9.9995e-01,  1.1218e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vdata in vqueue:\n",
    "    print(vdata['ego2global'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5aed6-ec3a-46ce-b73f-a542e0ef9227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb77ae9-c583-41b5-8254-f16df70a3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d21749-b825-4cb5-b617-a61d3d863c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e96f2-43ea-4d25-9df8-bdeadae5f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4f825-a7bd-441c-9030-0e4a8d10b8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6caaff5-3e71-49c5-94d0-7ef3bd69b924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66374ae5-6d20-4b13-92b5-85895e1a4ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673fe46-4ea7-474c-ae76-be90c2c5b8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f6be8-1a8f-4696-ab3b-393aa05cdfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44782bf5-203f-4433-9892-048208f08a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = data['img_inputs'][0] # (imgs, rots, trans, intrins, post_rots, post_trans)\n",
    "sample_token = data['img_metas'][0].data[0][0]['sample_idx']\n",
    "data['img_metas'] = data['img_metas'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d04163-e979-401d-b43b-19a40f37008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nuscenes inference\n",
    "# sum = 0\n",
    "# cnt = 0\n",
    "# for j in range(0, 100):\n",
    "#     cnt += 1\n",
    "#     data = next(data_iterator)\n",
    "    \n",
    "#     sample_token = data['img_metas'][0].data[0][0]['sample_idx']\n",
    "#     data['img_metas'] = data['img_metas'][0].data\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         data['points'][0].data[0][0] = data['points'][0].data[0][0].to(device)\n",
    "\n",
    "#         img_inputs = data['img_inputs'][0] # (imgs, rots, trans, intrins, post_rots, post_trans)\n",
    "\n",
    "#         for i, input_d in enumerate(img_inputs):\n",
    "#             img_inputs[i] = input_d.to(device)\n",
    "#         data['img_inputs'][0] = img_inputs\n",
    "#         # data['img_inputs'][0][0] = data['img_inputs'][0][0].to(device)\n",
    "\n",
    "#         starter.record()\n",
    "\n",
    "#         outputs = model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "#         ender.record()\n",
    "#         torch.cuda.synchronize()\n",
    "#         inference_time = starter.elapsed_time(ender)\n",
    "#         sum += inference_time\n",
    "#         print(\"inference time (ms): \", inference_time)\n",
    "# print(sum / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340117fb-76f5-4735-8afe-db27f5809877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nuscenes inference\n",
    "sample_token = data['img_metas'][0].data[0][0]['sample_idx']\n",
    "data['img_metas'] = data['img_metas'][0].data\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    data['points'][0].data[0][0] = data['points'][0].data[0][0].to(device)\n",
    "    \n",
    "    img_inputs = data['img_inputs'][0] # (imgs, rots, trans, intrins, post_rots, post_trans)\n",
    "    \n",
    "    for i, input_d in enumerate(img_inputs):\n",
    "        img_inputs[i] = input_d.to(device)\n",
    "    data['img_inputs'][0] = img_inputs\n",
    "    # data['img_inputs'][0][0] = data['img_inputs'][0][0].to(device)\n",
    "    \n",
    "    starter.record()\n",
    "    \n",
    "    outputs = model(return_loss=False, rescale=True, **data)\n",
    "    \n",
    "    ender.record()\n",
    "    torch.cuda.synchronize()\n",
    "    inference_time = starter.elapsed_time(ender)\n",
    "    print(\"inference time (ms): \", inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdc631-25ab-4b4c-96bf-7d52e00ea52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank, _ = get_dist_info()\n",
    "if rank == 0:\n",
    "    dataset.format_single_result(outputs, sample_idx, jsonfile_prefix='./output/')\n",
    "\n",
    "results_path = './output/pts_bbox/results_nusc.json'\n",
    "root_path = '../data/nuscenes'\n",
    "\n",
    "# load predicted results\n",
    "results = mmcv.load(results_path)['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df41df4-dfb8-4442-a27c-bda5ebbf03ee",
   "metadata": {},
   "source": [
    "## Nusc 기반 vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60982d-a139-4dff-aca2-ab90db11b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "views = [\n",
    "    'CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT',\n",
    "    'CAM_BACK', 'CAM_BACK_RIGHT'\n",
    "]\n",
    "\n",
    "info = infos[vis_idx]\n",
    "\n",
    "show_classes=[\n",
    "    'car',\n",
    "    'truck',\n",
    "    'construction_vehicle',\n",
    "    'bus',\n",
    "    'trailer',\n",
    "    'barrier',\n",
    "    'motorcycle',\n",
    "    'bicycle',\n",
    "    'pedestrian',\n",
    "    'traffic_cone',\n",
    "]\n",
    "\n",
    "# Set cameras\n",
    "threshold = 0.3\n",
    "show_range = 60\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(21, 8))\n",
    "\n",
    "imsize = (1600, 900)\n",
    "box_vis_level = BoxVisibility.ANY\n",
    "\n",
    "for i, k in enumerate(views):\n",
    "    # Draw camera views\n",
    "    fig_idx = i + 1 if i < 3 else i + 1\n",
    "    plt.subplot(2, 3, fig_idx)\n",
    "\n",
    "    # Set camera attributes\n",
    "    plt.title(k)\n",
    "    plt.axis('off')\n",
    "    plt.xlim(0, 1600)\n",
    "    plt.ylim(900, 0)\n",
    "\n",
    "    img = mmcv.imread(os.path.join(info['cams'][k]['data_path']))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw images\n",
    "    plt.imshow(img)\n",
    "\n",
    "    \"\"\"\n",
    "    Box: global => ego => lidar => sensor => image?\n",
    "      or global => ego => sensor => image?\n",
    "    \"\"\"\n",
    "    ego2global_translation = info['cams'][k]['ego2global_translation']\n",
    "    ego2global_rotation = info['cams'][k]['ego2global_rotation']\n",
    "    \n",
    "    lidar2ego_translation = info['lidar2ego_translation']\n",
    "    lidar2ego_rotation =  Quaternion(info['ego2global_rotation'])\n",
    "    \n",
    "    sensor2ego_trans = info['cams'][k]['sensor2ego_translation']\n",
    "    sensor2ego_rot = info['cams'][k]['sensor2ego_rotation']\n",
    "    \n",
    "    sensor2lidar_translation = info['cams'][k]['sensor2lidar_translation']\n",
    "    sensor2lidar_rotation = info['cams'][k]['sensor2lidar_rotation']\n",
    "    \n",
    "    intrinsic = info['cams'][k]['cam_intrinsic']\n",
    "    intrinsic = np.array(intrinsic)\n",
    "    \n",
    "    boxes_pred = []\n",
    "    for box_dict in list(results.values())[0]:\n",
    "        if box_dict['detection_score'] >= threshold and box_dict['detection_name'] in show_classes:\n",
    "            box = Box(\n",
    "                box_dict['translation'],\n",
    "                box_dict['size'],\n",
    "                Quaternion(box_dict['rotation']),\n",
    "                name=box_dict['detection_name']\n",
    "            )\n",
    "            \n",
    "            # box를 global => ego로 이동\n",
    "            box.translate(-np.array(ego2global_translation))\n",
    "            box.rotate(Quaternion(ego2global_rotation).inverse)\n",
    "            \n",
    "            # box를 ego => lidar로 이동\n",
    "            # box.translate(np.array(lidar2ego_translation))\n",
    "            # box.rotate(Quaternion(lidar2ego_rotation).inverse)\n",
    "            \n",
    "            # box를 lidar => camera로 이동\n",
    "            # box.translate(-np.array(sensor2lidar_translation))\n",
    "            # box.rotate(Quaternion(matrix=sensor2lidar_rotation).inverse)\n",
    "            \n",
    "            # box를 ego => camera로 이동\n",
    "            box.translate(-np.array(sensor2ego_trans))\n",
    "            box.rotate(Quaternion(sensor2ego_rot).inverse)\n",
    "            \n",
    "            if box_in_image(box, intrinsic, imsize, vis_level=box_vis_level):\n",
    "                c=cm.get_cmap('tab10')(show_classes.index(box.name))\n",
    "                \n",
    "                # box를 camera => image로 이동해서 render\n",
    "                box.render(plt, view=intrinsic, normalize=True, colors=(c, c, c))\n",
    "\n",
    "# Set legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(),\n",
    "           by_label.keys(),\n",
    "           loc='upper right',\n",
    "           framealpha=1)\n",
    "\n",
    "plt.tight_layout(w_pad=0, h_pad=2)\n",
    "# save_name ='output_%06d.jpg' % idx\n",
    "# plt.savefig(save_path+save_name)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6bae4d-54bf-4c99-b1e7-3dd8b3067eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnicv",
   "language": "python",
   "name": "omnicv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
